{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeremy/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jeremy/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jeremy/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jeremy/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jeremy/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jeremy/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fdf6ff1fd98>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib as matp\n",
    "import numpy as np\n",
    "from Hang.utils_u_groupnorm_pytorchLightning import *\n",
    "from utils import *\n",
    "import array as arr\n",
    "from torch.utils import data\n",
    "from numpy import zeros\n",
    "import time as time\n",
    "import pdb\n",
    "import nibabel as nib\n",
    "import torchvision.transforms\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "np.random.seed(0)\n",
    "random.seed(5)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [\"0001\",\"0017\",\"0018\",\"0038\",\"0040\",\"0042\",\"0046\",\"0087\",\"0090\",\"0108\",\"0116\",\"0131\",\"0178\",\"0190\",\n",
    "           \"0227\",\"0248\",\"0267\",\"0282\",\"0285\",\"0398\",\"0448\",\"0466\",\"0504\",\"0514\",\"0535\",\"0564\",\"0598\",\"0606\",\n",
    "           \"0607\",\"0618\",\"0620\",\"0623\",\"0642\",\"0646\",\"0655\",\"0668\",\"0675\",\"0681\",\"0719\",\"0761\",\"0762\",\"0783\",\n",
    "           \"0786\",\"0868\",\"0877\",\"0887\",\"0895\",\"0902\",\"0931\",\"0979\",\"1007\",\"1013\",\"1029\",\"1033\",\"1068\",\"1142\",\n",
    "           \"1143\",\"1163\",\"1190\",\"1260\",\"1275\",\"1347\",\"1383\",\"1389\",\"1416\",\"1435\",\"1441\",\"1447\",\"1451\",\"1514\",\n",
    "           \"1520\",\"1602\",\"1611\",\"1621\",\"1680\",\"1684\",\"1686\",\"1710\",\"1720\",\"1739\",\"1743\",\"1749\",\"1753\",\"1760\",\n",
    "           \"1795\",\"1805\",\"1845\",\"1858\",\"1876\",\"1889\",\"1892\",\"1898\",\"1899\",\"1918\",\"1924\",\"1932\",\"1952\",\"1961\",\n",
    "           \"1972\",\"1987\",\"2003\",\"2007\",\"2016\",\"2020\",\"2022\",\"2030\",\"2045\",\"2047\",\"2049\",\"2053\",\"2055\",\"2074\",\n",
    "           \"2077\",\"2080\",\"2091\",\"2094\",\"2103\",\"2115\",\"2128\",\"2142\",\"2144\",\"2146\",\"2152\",\"2156\",\"2158\",\"2160\",\n",
    "           \"2161\",\"2179\",\"2180\",\"2181\",\"2183\",\"2186\",\"2188\",\"2212\",\"2221\",\"2231\",\"2234\",\"2245\"]\n",
    "SPLIT = 50\n",
    "# numbers = numbers[SPLIT:SPLIT + 25]\n",
    "numbers = numbers[SPLIT + 25:]\n",
    "mni_numbers = ['2245']\n",
    "SIM_BRAIN = '2245'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = np.load(\"stats.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.67116852e+00, 4.64313265e+00],\n",
       "       [9.06276163e+01, 2.59251717e+01],\n",
       "       [9.00422508e+00, 8.18314496e+00],\n",
       "       [8.41492397e+00, 5.14438985e+00],\n",
       "       [6.72563369e+01, 1.34539774e+01],\n",
       "       [1.99994947e+03, 1.98949697e-01]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab 256x256 brains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = []\n",
    "masks_tight = []\n",
    "\n",
    "for number in numbers:\n",
    "    file_root = \"../\" + number + \"/\"\n",
    "    masks_tight.append(file_root + \"tightmask.nii.gz\")\n",
    "    masks.append(file_root + \"brain_mask.nii.gz\")\n",
    "\n",
    "mask_array, mask_array_tight = [], []\n",
    "\n",
    "for i in range(len(masks)):\n",
    "    mask_array.append(nib.load(masks[i]).get_fdata()) \n",
    "    mask_array_tight.append(nib.load(masks_tight[i]).get_fdata()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fname, masks, lesions = [], [], []\n",
    "w1, w2, w3 = [], [], []\n",
    "t1, t2, t3 = [], [], []\n",
    "\n",
    "for number in numbers:\n",
    "    file_root = \"../\" + number + \"/\"\n",
    "    masks.append(file_root + \"tightmask.nii.gz\")\n",
    "    lesions.append(file_root + \"lesion.nii.gz\")\n",
    "    fname.append(file_root + \"FASTT2_FULL.nii.gz\")\n",
    "    w1.append(file_root + \"w1.nii.gz\")\n",
    "    w2.append(file_root + \"w2.nii.gz\")\n",
    "    w3.append(file_root + \"w3.nii.gz\")\n",
    "    t1.append(file_root + \"t1.nii.gz\")\n",
    "    t2.append(file_root + \"t2.nii.gz\")\n",
    "    t3.append(file_root + \"t3.nii.gz\")\n",
    "\n",
    "mask_array, lesion_mask_array = [], []\n",
    "brains, labels = [], []\n",
    "\n",
    "brain2245, label2245 = [], []\n",
    "mask2245, lesion2245 = [], []\n",
    "\n",
    "for i in range(len(masks)):\n",
    "    mask_array.append(nib.load(masks[i]).get_fdata()) \n",
    "    if (numbers[i] == SIM_BRAIN):\n",
    "        mask2245 = nib.load(masks[i]).get_fdata()[None]\n",
    "    \n",
    "for i in range(len(lesions)):\n",
    "    data = nib.load(lesions[i]).get_fdata()\n",
    "    data[data >= 1] = 1\n",
    "    lesion_mask_array.append(data) \n",
    "    if (numbers[i] == SIM_BRAIN):\n",
    "        lesion2245 = data[None]\n",
    "\n",
    "for i in range(len(masks)):\n",
    "    brain = []\n",
    "    for j in range(6):\n",
    "        brain.append(nib.load(fname[i]).get_fdata()[:,:,:,j]  * mask_array[i])\n",
    "    brains.append(brain)\n",
    "    if (numbers[i] == SIM_BRAIN):\n",
    "        brain2245 = np.array(brain)[None]\n",
    "        \n",
    "for i in range(len(masks)):\n",
    "    label = []\n",
    "    label.append(nib.load(w1[i]).get_fdata() * mask_array[i])\n",
    "    label.append(nib.load(w2[i]).get_fdata() * mask_array[i])\n",
    "    label.append(nib.load(w3[i]).get_fdata() * mask_array[i])\n",
    "    label.append(nib.load(t1[i]).get_fdata() * mask_array[i])\n",
    "    label.append(nib.load(t2[i]).get_fdata() * mask_array[i])\n",
    "    label.append(nib.load(t3[i]).get_fdata() * mask_array[i]) \n",
    "    labels.append(label)\n",
    "    if (numbers[i] == SIM_BRAIN):\n",
    "        label2245 = np.array(label)[None]\n",
    "\n",
    "labels = np.array(labels)\n",
    "brains = np.array(brains)\n",
    "mask_array = np.array(mask_array)\n",
    "lesion_mask_array = np.array(lesion_mask_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateBrains(brainRef, labels, masks, noise):\n",
    "    label = labels[0].copy()\n",
    "    brains = np.zeros((NUM_BRAINS,)+label.shape)\n",
    "    echoTimes = [0, 7.5, 17.5, 67.5, 147.5, 307.5]\n",
    "    for labelIdx in range(len(labels)):\n",
    "        label = labels[labelIdx].copy()\n",
    "        for i in range(6):\n",
    "            brains[labelIdx,i] = label[0] * np.exp(-echoTimes[i] / (label[3] + 1e-16)) + \\\n",
    "                                 label[1] * np.exp(-echoTimes[i] / (label[4] + 1e-16)) + \\\n",
    "                                 label[2] * np.exp(-echoTimes[i] / (label[5] + 1e-16))\n",
    "            np.nan_to_num(brains[labelIdx,i], copy=False)\n",
    "        scale = brainRef[labelIdx,0] / (brains[labelIdx,0] + 1e-16)\n",
    "        for i in range(6):\n",
    "            brains[labelIdx,i] *= scale\n",
    "    brains += noise\n",
    "    for i in range(6):\n",
    "        brains[:,i] *= masks\n",
    "    return brains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Segmentation to mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reproMaskFiles = []\n",
    "reproFiles = []\n",
    "reproMWFFiles = []\n",
    "\n",
    "reproNumbers = ['125545', '093924', '151026', '111721', '093923', '151025', '113308', '113307', '171732', '101851', \n",
    "                '125546', '163835', '163834', '154655', '101850', '175630', '175631', '184052', '111720', '184051']\n",
    "for number in reproNumbers:\n",
    "    file_root = \"../\" + number + \"/\"\n",
    "    reproMaskFiles.append(file_root + \"tightmask.nii.gz\")\n",
    "    reproFiles.append(file_root + \"FASTT2_FULL.nii.gz\")\n",
    "    reproMWFFiles.append(file_root + \"MWF.nii.gz\")\n",
    "\n",
    "reproMasks = []\n",
    "reproBrains = []\n",
    "reproMWFs = []\n",
    "for mask in reproMaskFiles:\n",
    "    mask = nib.load(mask).get_fdata()\n",
    "    reproMasks.append(mask)\n",
    "\n",
    "for file_idx in range(len(reproFiles)):\n",
    "    file = reproFiles[file_idx]\n",
    "    brain = []\n",
    "    for j in range(6):\n",
    "        brain.append(nib.load(file).get_fdata()[:,:,:,j]  * reproMasks[file_idx])\n",
    "    reproBrains.append(brain)\n",
    "    \n",
    "for img in reproMWFFiles:\n",
    "    img = nib.load(img).get_fdata()\n",
    "    reproMWFs.append(img[None])\n",
    "\n",
    "reproMasks = np.array(reproMasks)\n",
    "reproBrains = np.array(reproBrains)\n",
    "reproMWFs = np.array(reproMWFs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Hang.unet3dPersonalGroupNorm_pytorchLightning import unet3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateResultsErrorTable(state_dicts, stats, testBrains, testLabels, testMasks, numbers, lesions = None, \n",
    "                               save=False, brainType = \"real\", lesion = False):\n",
    "    featureNumPaths = [\"MWF\", \"IEWF\", \"CSFF\", \"MWF_T2\", \"IEWF_T2\", \"CSFF_T2\"]\n",
    "    for state_dict in state_dicts:\n",
    "        model = unet3d(0.01,0.0012, is_deconv = False, weight=50).float()\n",
    "        weight = state_dict.split(\"/\")[-1].split(\".\")[0]\n",
    "        state_dict = torch.load(state_dict, map_location='cpu')\n",
    "        model.load_state_dict(state_dict[\"state_dict\"])\n",
    "        model = model.float().cuda()\n",
    "        model.eval()\n",
    "        results = {}\n",
    "        results[0] = []\n",
    "        results[1] = []\n",
    "        results[2] = []\n",
    "        results[3] = []\n",
    "        results[4] = []\n",
    "        results[5] = []\n",
    "        size = testBrains.shape[2:] \n",
    "        part = ()\n",
    "        \n",
    "        for idx in range(len(testBrains)): \n",
    "            number = numbers[idx] if len(testBrains) == len(numbers) else 'average'\n",
    "            mask = testMasks[idx]\n",
    "            signal = np.divide(testBrains[idx], testBrains[idx][0] + 1e-16)[None]\n",
    "            output = model(torch.tensor(signal).float().cuda()).cuda()\n",
    "            label = testLabels[idx].copy()\n",
    "            for i in range(len(stats)):\n",
    "                output[0,i] *= stats[i][1]\n",
    "                output[0,i] += stats[i][0]\n",
    "            output = output.detach().cpu().numpy()\n",
    "\n",
    "            guess_sum = output[0,0]+output[0,1]+output[0,2]+1e-16\n",
    "            output[0,0] /= guess_sum\n",
    "            output[0,1] /= guess_sum\n",
    "            output[0,2] /= guess_sum\n",
    "            output[0,0] *= 100\n",
    "            output[0,1] *= 100\n",
    "            output[0,2] *= 100\n",
    "\n",
    "            if (label.shape[0] != 1):\n",
    "                guess_sum_label = label[0] + label[1] + label[2]+1e-16\n",
    "                label[0] /= guess_sum_label\n",
    "                label[1] /= guess_sum_label\n",
    "                label[2] /= guess_sum_label\n",
    "                label[0] *= 100\n",
    "                label[1] *= 100\n",
    "                label[2] *= 100\n",
    "            \n",
    "            label = np.nan_to_num(label).astype(float)\n",
    "            output = np.nan_to_num(output).astype(float)\n",
    "            output = output[0]\n",
    "            \n",
    "            for feature_num in range(min(6, len(label))):\n",
    "                if (lesion):\n",
    "                    lesionMask = lesions[idx]\n",
    "                    if (lesionMask.sum() == 0):\n",
    "                        continue\n",
    "                    brain = np.zeros(output[0].shape, dtype=float)\n",
    "                    label_big = np.zeros(output[0].shape, dtype=float)\n",
    "                    min_val = -3000\n",
    "                    max_val = 3000\n",
    "                    if (feature_num == 0):\n",
    "                        min_val = 0\n",
    "                        max_val = 100\n",
    "                    brain = np.clip(output[feature_num] * mask, min_val, max_val)\n",
    "                    brain = brain * lesionMask\n",
    "                    label_big = label[feature_num] * mask\n",
    "                    label_big =  label_big * lesionMask\n",
    "                    error = abs(-label_big+brain)\n",
    "                    error = error[lesionMask == 1]\n",
    "                    results[feature_num].append(np.mean(error))\n",
    "                else:\n",
    "                    brain = np.zeros(output[0].shape, dtype=float)\n",
    "                    label_big = np.zeros(output[0].shape, dtype=float)\n",
    "                    min_val = -3000\n",
    "                    max_val = 3000\n",
    "                    if (feature_num == 0):\n",
    "                        min_val = 0\n",
    "                        max_val = 100\n",
    "                    brain = np.clip(output[feature_num] * mask, min_val, max_val)\n",
    "                    label_big =  label[feature_num] * mask\n",
    "                    error = abs(-label_big+brain)\n",
    "                    error = error[mask == 1]\n",
    "                    results[feature_num].append(np.mean(error))\n",
    "                    if (save):\n",
    "                        brain = brain\n",
    "                        label_big = label_big\n",
    "                        brainT = np.zeros(size)\n",
    "                        labelT = np.zeros(size)\n",
    "                        brainT[part] = brain\n",
    "                        labelT[part] = label_big\n",
    "                        label_big = labelT\n",
    "                        brain = brainT\n",
    "                        base = f\"results/0_weight_new/{featureNumPaths[feature_num]}/\" #  2222\n",
    "                        sample = f\"../{number}/w1.nii.gz\" if number != \"average\" else \"\"\n",
    "                        if (len(number) > 5):\n",
    "                            sample = f\"../{number}/MWF.nii.gz\" if number != \"average\" else \"\"\n",
    "                        sample = sample if (\"MNI\" not in brainType and \"mni\" not in brainType) else \"\"\n",
    "                        save_nii(brain, base+f\"{number}_pred_UNET_{brainType}.nii.gz\", sample)\n",
    "                        save_nii(label_big, base+f\"{number}_label_UNET_{brainType}.nii.gz\", sample)\n",
    "                        save_nii(brain-label_big, base+f\"{number}_err_UNET_{brainType}.nii.gz\", sample)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save 256x256 test brains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dicts = [\"../unetpp_big_gpu0/_ckpt_epoch_56.ckpt\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [i for i in os.listdir(\"../unetpp_big_gpu0\") if i[0] == '_']\n",
    "nums = sorted([int(i.split(\"_\")[3].split(\".\")[0]) for i in files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['../unetpp_big_gpu0/_ckpt_epoch_' + str(i) + '.ckpt' for i in nums]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "res256 = calculateResultsErrorTable(state_dicts, stats, brains, labels, mask_array, numbers, save=True, \n",
    "                                    brainType='256real')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7261852746776314 0.25554731522405366\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(res256[0]), np.std(res256[0])) #MAE for L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "res256Lesion = calculateResultsErrorTable(state_dicts, stats, brains, labels, mask_array, numbers, lesion_mask_array,\n",
    "                                          lesion = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.742977548145684 0.3848298400963046\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(res256Lesion[0]), np.std(res256Lesion[0])) #MAE for L2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save 256x256 simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulate brain 1260 in 256x256 space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [1:38:06<00:00, 11.77s/it]\n"
     ]
    }
   ],
   "source": [
    "res256snr200 = []\n",
    "res256snr200Lesion = []\n",
    "res256snr100 = []\n",
    "res256snr100Lesion = []\n",
    "res256snr50 = []\n",
    "res256snr50Lesion = []\n",
    "res256snr25 = []\n",
    "res256snr25Lesion = []\n",
    "\n",
    "\n",
    "minSum200 = 10000\n",
    "minSum100 = 10000\n",
    "minSum50 = 10000\n",
    "minSum25 = 10000\n",
    "\n",
    "for i in tqdm(range(500)):\n",
    "    '''Generating Brain'''\n",
    "    NUM_BRAINS = len(brain2245)\n",
    "    SNR = 200\n",
    "    roi = load_nii(\"roi.nii.gz\")\n",
    "    noise = np.random.normal(size=(NUM_BRAINS,) + label2245[0].shape, scale=(brain2245[0,0][roi == 1].mean()/SNR))\n",
    "    simBrains256_snr200 = generateBrains(brain2245, label2245, mask2245, noise)\n",
    "    SNR = 100\n",
    "    noise = np.random.normal(size=(NUM_BRAINS,) + label2245[0].shape, scale=(brain2245[0,0][roi == 1].mean()/SNR))\n",
    "    simBrains256_snr100 = generateBrains(brain2245, label2245, mask2245, noise)\n",
    "    SNR = 50\n",
    "    noise = np.random.normal(size=(NUM_BRAINS,) + label2245[0].shape, scale=(brain2245[0,0][roi == 1].mean()/SNR))\n",
    "    simBrains256_snr50 = generateBrains(brain2245, label2245, mask2245, noise)\n",
    "    SNR = 25\n",
    "    noise = np.random.normal(size=(NUM_BRAINS,) + label2245[0].shape, scale=(brain2245[0,0][roi == 1].mean()/SNR))\n",
    "    simBrains256_snr25 = generateBrains(brain2245, label2245, mask2245, noise)\n",
    "    \n",
    "    '''Testing Brain'''\n",
    "    tempRes = calculateResultsErrorTable(state_dicts, stats, simBrains256_snr200, label2245, mask2245, [SIM_BRAIN], \n",
    "                                         save=False, brainType='256sim_snr200')\n",
    "    tempResLesion = calculateResultsErrorTable(state_dicts, stats, simBrains256_snr200, label2245, mask2245, \n",
    "                                               [SIM_BRAIN], lesion2245, save=False, lesion=True)\n",
    "    res256snr200.append(tempRes)\n",
    "    res256snr200Lesion.append(tempResLesion)\n",
    "    if (sum(tempRes) < minSum200):\n",
    "        minSum200 = sum(tempRes)\n",
    "        tempRes = calculateResultsErrorTable(state_dicts, stats, simBrains256_snr200, label2245, mask2245, [SIM_BRAIN], \n",
    "                                             save=True, brainType='256sim_snr200')\n",
    "\n",
    "    tempRes = calculateResultsErrorTable(state_dicts, stats, simBrains256_snr100, label2245, mask2245, [SIM_BRAIN], \n",
    "                                         save=False, brainType='256sim_snr100')\n",
    "    tempResLesion = calculateResultsErrorTable(state_dicts, stats, simBrains256_snr100, label2245, mask2245, \n",
    "                                               [SIM_BRAIN], lesion2245, save=False, lesion=True)\n",
    "    res256snr100.append(tempRes)\n",
    "    res256snr100Lesion.append(tempResLesion)\n",
    "    if (sum(tempRes) < minSum100):\n",
    "        minSum100 = sum(tempRes)\n",
    "        tempRes = calculateResultsErrorTable(state_dicts, stats, simBrains256_snr100, label2245, mask2245, [SIM_BRAIN], \n",
    "                                             save=True, brainType='256sim_snr100')\n",
    "        \n",
    "    tempRes = calculateResultsErrorTable(state_dicts, stats, simBrains256_snr50, label2245, mask2245, [SIM_BRAIN], \n",
    "                                         save=False, brainType='256sim_snr50')\n",
    "    tempResLesion = calculateResultsErrorTable(state_dicts, stats, simBrains256_snr50, label2245, mask2245, \n",
    "                                         [SIM_BRAIN], lesion2245,  save=False, lesion=True)\n",
    "    res256snr50.append(tempRes)\n",
    "    res256snr50Lesion.append(tempResLesion)\n",
    "    if (sum(tempRes) < minSum50):\n",
    "        minSum50 = sum(tempRes)\n",
    "        tempRes = calculateResultsErrorTable(state_dicts, stats, simBrains256_snr50, label2245, mask2245, [SIM_BRAIN], \n",
    "                                             save=True, brainType='256sim_snr50')\n",
    "        \n",
    "    tempRes = calculateResultsErrorTable(state_dicts, stats, simBrains256_snr25, label2245, mask2245, [SIM_BRAIN], \n",
    "                                         save=False, brainType='256sim_snr25')\n",
    "    tempResLesion = calculateResultsErrorTable(state_dicts, stats, simBrains256_snr25, label2245, mask2245, \n",
    "                                         [SIM_BRAIN], lesion2245,  save=False, lesion=True)\n",
    "    res256snr25.append(tempRes)\n",
    "    res256snr25Lesion.append(tempResLesion)\n",
    "    if (sum(tempRes) < minSum25):\n",
    "        minSum25 = sum(tempRes)\n",
    "        tempRes = calculateResultsErrorTable(state_dicts, stats, simBrains256_snr25, label2245, mask2245, [SIM_BRAIN], \n",
    "                                             save=True, brainType='256sim_snr25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "res256snr200Avg = compressResults(res256snr200)\n",
    "res256snr100Avg = compressResults(res256snr100)\n",
    "res256snr50Avg = compressResults(res256snr50)\n",
    "res256snr25Avg = compressResults(res256snr25)\n",
    "\n",
    "res256snr200LesionAvg = compressResults(res256snr200Lesion)\n",
    "res256snr100LesionAvg = compressResults(res256snr100Lesion)\n",
    "res256snr50LesionAvg = compressResults(res256snr50Lesion)\n",
    "res256snr25LesionAvg = compressResults(res256snr25Lesion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "simData = [res256snr200, res256snr100, res256snr50, res256snr25]\n",
    "simDataLesion = [res256snr200Lesion, res256snr100Lesion, res256snr50Lesion, res256snr25Lesion]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Repro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "resRepro = calculateResultsErrorTable(state_dicts, stats, reproBrains, reproMWFs, reproMasks, reproNumbers, \n",
    "                                      save=True, brainType='repro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeremy/.local/lib/python3.6/site-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    }
   ],
   "source": [
    "np.save(\"unetData.npy\", [res256, res256Lesion, \n",
    "                        res256snr200Avg, res256snr100Avg, res256snr50Avg, res256snr25Avg,\n",
    "                        res256snr200LesionAvg, res256snr100LesionAvg, res256snr50LesionAvg, res256snr25LesionAvg,\n",
    "                        resRepro, simData, simDataLesion], allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "notify_time": "5"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
